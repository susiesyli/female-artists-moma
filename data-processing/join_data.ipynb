{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2_/mdjrqzks7tj2_q8gf6cl0s6w0000gn/T/ipykernel_69395/1444104914.py:7: DtypeWarning: Columns (2,8,12,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  artworks_df = pd.read_csv('female_artworks.csv')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"55.8801117602\" doesn't match format \"%Y-%m-%d\", at position 1113. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m artists_json\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 46\u001b[0m     processed_data \u001b[39m=\u001b[39m process_data()\n\u001b[1;32m     47\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessed \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(processed_data)\u001b[39m}\u001b[39;00m\u001b[39m artists\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m artists_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mfemale_artists_with_work_counts.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Clean up artworks data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Convert DateAcquired to datetime and extract year\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m artworks_df[\u001b[39m'\u001b[39m\u001b[39mAcquisitionYear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_datetime(artworks_df[\u001b[39m'\u001b[39;49m\u001b[39mDateAcquired\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39myear\n\u001b[1;32m     14\u001b[0m \u001b[39m# Get first acquisition year for each artist\u001b[39;00m\n\u001b[1;32m     15\u001b[0m first_acquisitions \u001b[39m=\u001b[39m artworks_df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mConstituentID\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mAcquisitionYear\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmin()\u001b[39m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mtz_localize(\u001b[39m\"\u001b[39m\u001b[39mutc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1062\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1063\u001b[0m     cache_array \u001b[39m=\u001b[39m _maybe_cache(arg, \u001b[39mformat\u001b[39;49m, cache, convert_listlike)\n\u001b[1;32m   1064\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cache_array\u001b[39m.\u001b[39mempty:\n\u001b[1;32m   1065\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    245\u001b[0m unique_dates \u001b[39m=\u001b[39m unique(arg)\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(unique_dates) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(arg):\n\u001b[0;32m--> 247\u001b[0m     cache_dates \u001b[39m=\u001b[39m convert_listlike(unique_dates, \u001b[39mformat\u001b[39;49m)\n\u001b[1;32m    248\u001b[0m     \u001b[39m# GH#45319\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmixed\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[39mformat\u001b[39;49m, exact, errors)\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[39m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[39m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[39m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[39m=\u001b[39m array_strptime(arg, fmt, exact\u001b[39m=\u001b[39;49mexact, errors\u001b[39m=\u001b[39;49merrors, utc\u001b[39m=\u001b[39;49mutc)\n\u001b[1;32m    468\u001b[0m     \u001b[39mif\u001b[39;00m tz_out \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdatetime_data(result\u001b[39m.\u001b[39mdtype)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"55.8801117602\" doesn't match format \"%Y-%m-%d\", at position 1113. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# # Read the CSV files\n",
    "# def process_data():\n",
    "#     # Read the datasets\n",
    "#     artworks_df = pd.read_csv('female_artworks.csv')\n",
    "#     artists_df = pd.read_csv('female_artists_with_work_counts.csv')\n",
    "    \n",
    "#     # Clean up artworks data\n",
    "#     # Convert DateAcquired to datetime and extract year\n",
    "#     artworks_df['AcquisitionYear'] = pd.to_datetime(artworks_df['DateAcquired']).dt.year\n",
    "    \n",
    "#     # Get first acquisition year for each artist\n",
    "#     first_acquisitions = artworks_df.groupby('ConstituentID')['AcquisitionYear'].min().reset_index()\n",
    "#     first_acquisitions = first_acquisitions.rename(columns={'AcquisitionYear': 'FirstAcquisitionYear'})\n",
    "    \n",
    "#     # Merge with artists data\n",
    "#     merged_df = artists_df.merge(first_acquisitions, on='ConstituentID', how='left')\n",
    "    \n",
    "#     # Select relevant columns\n",
    "#     final_df = merged_df[[\n",
    "#         'ConstituentID',\n",
    "#         'DisplayName',\n",
    "#         'Nationality',\n",
    "#         'BeginDate',\n",
    "#         'artwork_count',\n",
    "#         'FirstAcquisitionYear'\n",
    "#     ]].copy()\n",
    "    \n",
    "#     # Group artists by nationality for clustering\n",
    "#     nationalities = final_df['Nationality'].unique()\n",
    "#     nationality_map = {nat: idx for idx, nat in enumerate(nationalities)}\n",
    "#     final_df['NationalityGroup'] = final_df['Nationality'].map(nationality_map)\n",
    "    \n",
    "#     # Convert to JSON for the visualization\n",
    "#     artists_json = final_df.to_dict(orient='records')\n",
    "    \n",
    "#     # Save processed data\n",
    "#     with open('processed_artists.json', 'w') as f:\n",
    "#         json.dump(artists_json, f)\n",
    "    \n",
    "#     return artists_json\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     processed_data = process_data()\n",
    "#     print(f\"Processed {len(processed_data)} artists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cc7239228f96f60021c839d45e73f0469089d31d4a341e8e753c0ae0a151559"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
